{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvTXpH_kqIDy"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "American Sign Language (ASL) is a complete, complex language that employs signs made by moving the\n",
        "hands combined with facial expressions and postures of the body. It is the primary language of many\n",
        "North Americans who are deaf and is one of several communication options used by people who are deaf or\n",
        "hard-of-hearing. The hand gestures representing English alphabet are shown below. This lab focuses on classifying a subset\n",
        "of these hand gesture images using convolutional neural networks. Specifically, given an image of a hand\n",
        "showing one of the letters A-I, we want to detect which letter is being represented.\n",
        "\n",
        "![alt text](https://www.disabled-world.com/pics/1/asl-alphabet.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiDuQaAh56sT"
      },
      "source": [
        "### 1. Data Loading and Splitting\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "WBrH5kBqRLa6",
        "jupyter": {
          "outputs_hidden": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8faa1843-2fbd-4ec8-f284-a3a05e06698f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7e58c04d8eb0>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "#all the imported libraries would go here\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import math\n",
        "from math import floor\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "torch.manual_seed(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "#mounting the drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#importing dataset from drive\n",
        "path = '/content/drive/My Drive/Colab Notebooks/APS 360/Lab3 Dataset/'\n",
        "\n",
        "classes = ('A', 'B', 'C', 'D', 'E', 'F', 'G','H', 'I')\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Resize((224,224))]\n",
        ")\n",
        "\n",
        "dataset = torchvision.datasets.ImageFolder(path, transform = transform)\n",
        "\n",
        "#splitting training, validation and test\n",
        "np.random.seed(1000)\n",
        "\n",
        "indices = np.arange(len(dataset))\n",
        "\n",
        "np.random.shuffle(indices)\n",
        "train_split = int(len(indices)*0.6) #split 60/40\n",
        "train_indices, other_indices = indices[:train_split], indices[train_split:]\n",
        "val_test_split = int(len(other_indices)*0.5) #50/50 split between test and validation\n",
        "val_indices, test_indices = other_indices[:val_test_split], other_indices[val_test_split:]\n",
        "\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "val_sampler = SubsetRandomSampler(val_indices)\n",
        "test_sampler = SubsetRandomSampler(test_indices)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size = 30, num_workers = 1, sampler = train_sampler)\n",
        "val_loader = torch.utils.data.DataLoader(dataset, batch_size = 30, num_workers = 1, sampler = val_sampler)\n",
        "test_loader = torch.utils.data.DataLoader(dataset, batch_size = 30, num_workers = 1, sampler = test_sampler)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0eXgcMw0a5a",
        "outputId": "fbb1aec3-3b0a-4599-e82c-9a61f75eef72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)"
      ],
      "metadata": {
        "id": "elX0XMpZt1lt",
        "outputId": "95d98eb6-ec28-4227-e017-9c1eb0d70e2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset ImageFolder\n",
            "    Number of datapoints: 2219\n",
            "    Root location: /content/drive/My Drive/Colab Notebooks/APS 360/Lab3 Dataset/\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=warn)\n",
            "           )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total number of images in dataset:\" + str(len(dataset)))\n",
        "print(\"Number of images in training set:\" + str(len(train_loader)))\n",
        "print(\"Number of images in validation set:\" + str(len(val_loader)))\n",
        "print(\"Number of images in test set:\" + str(len(test_loader)))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2B2e8iJ4ITP-",
        "outputId": "a1c3acc7-b4b4-44c9-a79e-027293f9da83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of images in dataset:2219\n",
            "Number of images in training set:45\n",
            "Number of images in validation set:15\n",
            "Number of images in test set:15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VWX4DGY5gQE"
      },
      "source": [
        "### 2. Model Building and Sanity Checking\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class CNN_Classifier(nn.Module):\n",
        "  def __init__(self, name= \"CNN_Classifier\"):\n",
        "    super(CNN_Classifier,self).__init__()\n",
        "    self.name= name\n",
        "    self.conv1 = nn.Conv2d(3,5,10)\n",
        "    self.pool = nn.MaxPool2d(2,2)\n",
        "    self.conv2 = nn.Conv2d(5,10,5)\n",
        "\n",
        "\n",
        "    #using the output formula from notes\n",
        "    self.size1 = floor((224-10+1)/2)\n",
        "    self.size2 = floor((self.size1 - 5 +1)/2)\n",
        "\n",
        "    self.linsize = 10*self.size2*self.size2\n",
        "    self.fc1 = nn.Linear(self.linsize, 32)\n",
        "    self.fc2 = nn.Linear(32,1)\n",
        "\n",
        "  def forward(self,img):\n",
        "   x = self.pool(F.relu(self.conv1(img)))\n",
        "   x = self.pool(F.relu(self.conv2(x)))\n",
        "   x = x.view(-1, self.linsize)\n",
        "   x = F.relu(self.fc1(x))\n",
        "   x=self.fc2(x)\n",
        "   x=x.squeeze(1)\n",
        "\n",
        "   return x\n",
        "\n"
      ],
      "metadata": {
        "id": "VA7_Swe6PUaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeGvelvb515e"
      },
      "source": [
        "### Training Code\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_model_name(name, batch_size, learning_rate, epoch):\n",
        "  model_path = \"model_{0}_bc{1}_lr{2}_epoch{3}\".format(name,\n",
        "                                                       batch_size,\n",
        "                                                       learning_rate,\n",
        "                                                       epoch)\n",
        "  return model_path"
      ],
      "metadata": {
        "id": "YkVCW-yCLA_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_accuracy(model, loader):\n",
        "  correct =0\n",
        "  total = 0\n",
        "\n",
        "  for batch in loader:\n",
        "    for image,labels in batch:\n",
        "      print(\"start\")\n",
        "      output = model(images)\n",
        "    print(\"finish\")\n",
        "    pred = output.max(-1, keepdim = True)[1]\n",
        "    correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "    total+= images.shape[0]\n",
        "\n",
        "  return correct/total"
      ],
      "metadata": {
        "id": "KfE-2XmkwFSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_label(labels):\n",
        "\n",
        "    max_val = torch.max(labels)\n",
        "    min_val = torch.min(labels)\n",
        "    norm_labels = (labels - min_val)/(max_val - min_val)\n",
        "    return norm_labels"
      ],
      "metadata": {
        "id": "YPEvAu775fNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(net, loader, criterion):\n",
        "\n",
        "    total_loss = 0.0\n",
        "    total_err = 0.0\n",
        "    total_epoch = 0\n",
        "    for i, data in enumerate(loader, 0):\n",
        "        inputs, labels = data\n",
        "        labels = normalize_label(labels)  # Convert labels to 0/1\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels.float())\n",
        "        corr = (outputs > 0.0).squeeze().long() != labels\n",
        "        total_err += int(corr.sum())\n",
        "        total_loss += loss.item()\n",
        "        total_epoch += len(labels)\n",
        "    err = float(total_err) / total_epoch\n",
        "    loss = float(total_loss) / (i + 1)\n",
        "    return err"
      ],
      "metadata": {
        "id": "21JrPm385QRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "17YTQv4l54W1",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, val_Loader, learning_rate = 0.01, batch_size = 64, num_epochs = 30):\n",
        "  torch.manual_seed(1000)\n",
        "\n",
        "\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "  optimizer = optim.SGD(model.parameters(), lr = learning_rate, momentum = 0.9)\n",
        "\n",
        "  iters, losses, train_err, val_err = [], [], [], []\n",
        "\n",
        "\n",
        "\n",
        "  n=0\n",
        "  for epoch in range(num_epochs):\n",
        "\n",
        "\n",
        "    for images, labels in iter(train_loader):\n",
        "\n",
        "      #if use_cuda and torch.cuda.is_available():\n",
        "        #images = images.cuda()\n",
        "        #labels = labels.cuda()\n",
        "\n",
        "      out = model(images)\n",
        "      loss = criterion(out,labels.float())\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "    iters.append(n)\n",
        "    losses.append(float(loss)/batch_size)\n",
        "    train_err.append(evaluate(model, train_loader,criterion))\n",
        "    val_err.append(evaluate(model, val_loader,criterion))\n",
        "    n+= 1\n",
        "\n",
        "    #train_acc[epoch]=get_accuracy(model, train_loader)\n",
        "    #val_acc[epoch]=get_accuracy(model, val_loader)\n",
        "    #losses.append(float(loss)/batch_size)\n",
        "\n",
        "    print((\"Epoch: {} Train err: {}  Validation err: {}\"). format(epoch + 1,\n",
        "                                                                           train_err[epoch],\n",
        "                                                                           val_err[epoch]))\n",
        "    model_path = get_model_name(model.name, batch_size, learning_rate, epoch)\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "\n",
        "\n",
        "  epochs = np.arange(1, num_epochs + 1)\n",
        "\n",
        "  return train_err, val_err, epochs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "lXYRBhQO6d3u",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "#for overfitting, I would use the train function with a very low learning rate and more epochs\n",
        "model = CNN_Classifier()\n",
        "#for train_loader and val_loader, I would collect 10-20 sign language images and process them as shown in Part 1 - Data Handling with a 60/20/20 split\n",
        "overfitting = train(model, train_loader, val_loader,learning_rate = 0.001, batch_size = 64, num_epochs = 100 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXRQbgMqR_Qy",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "def plot_val_train(path):\n",
        "\n",
        "  plt.title(\"Train vs Validation Error\")\n",
        "  n = len(train_err) # number of epochs\n",
        "  plt.plot(range(1,n+1), train_err, label=\"Train\")\n",
        "  plt.plot(range(1,n+1), val_err, label=\"Validation\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Error\")\n",
        "  plt.legend(loc='best')\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CNN = CNN_Classifier()\n",
        "print(CNN)\n",
        "train_err, val_err, epochs = train(CNN, train_loader, val_loader)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2n4sxyB_V5l",
        "outputId": "a839d50f-cc1a-478d-c8ba-455aa8ecf805"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN_Classifier(\n",
            "  (conv1): Conv2d(3, 5, kernel_size=(10, 10), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(5, 10, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=26010, out_features=32, bias=True)\n",
            "  (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 Train err: 0.8812922614575507  Validation err: 0.8918918918918919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2 Train err: 0.873779113448535  Validation err: 0.8918918918918919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3 Train err: 0.8715251690458302  Validation err: 0.8918918918918919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4 Train err: 0.8797896318557475  Validation err: 0.8918918918918919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5 Train err: 0.8797896318557475  Validation err: 0.8896396396396397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 6 Train err: 0.8797896318557475  Validation err: 0.8918918918918919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 7 Train err: 0.8812922614575507  Validation err: 0.8806306306306306\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 8 Train err: 0.8760330578512396  Validation err: 0.8828828828828829\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 9 Train err: 0.8797896318557475  Validation err: 0.8918918918918919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 Train err: 0.8812922614575507  Validation err: 0.8918918918918919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 11 Train err: 0.8760330578512396  Validation err: 0.8761261261261262\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 12 Train err: 0.8707738542449286  Validation err: 0.8828828828828829\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 13 Train err: 0.8812922614575507  Validation err: 0.8918918918918919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 14 Train err: 0.8775356874530428  Validation err: 0.8851351351351351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 15 Train err: 0.8812922614575507  Validation err: 0.8851351351351351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 16 Train err: 0.8805409466566492  Validation err: 0.8783783783783784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 17 Train err: 0.8812922614575507  Validation err: 0.8918918918918919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 18 Train err: 0.8782870022539444  Validation err: 0.8873873873873874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 19 Train err: 0.873779113448535  Validation err: 0.8918918918918919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 20 Train err: 0.8812922614575507  Validation err: 0.8851351351351351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 21 Train err: 0.8812922614575507  Validation err: 0.8918918918918919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 22 Train err: 0.8775356874530428  Validation err: 0.8671171171171171\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 23 Train err: 0.8745304282494365  Validation err: 0.8918918918918919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 24 Train err: 0.8812922614575507  Validation err: 0.8918918918918919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 25 Train err: 0.8812922614575507  Validation err: 0.8918918918918919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 26 Train err: 0.8797896318557475  Validation err: 0.8828828828828829\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 27 Train err: 0.8797896318557475  Validation err: 0.8918918918918919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 28 Train err: 0.8752817430503381  Validation err: 0.8918918918918919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 29 Train err: 0.8805409466566492  Validation err: 0.8828828828828829\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 30 Train err: 0.8760330578512396  Validation err: 0.8783783783783784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title(\"Train vs Validation Error\")\n",
        "plt.plot(epochs, train_err, label=\"Train\")\n",
        "plt.plot(epochs, val_err, label=\"Validation\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Error\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "808fR_YVXCUv",
        "outputId": "860c1d3e-e0aa-4e82-a527-fccbdf972626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "BJKcTW9C7TZk",
        "jupyter": {
          "outputs_hidden": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c638e5e0-838a-4c29-bf0d-eb9c76d72692"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|██████████| 233M/233M [00:01<00:00, 239MB/s]\n"
          ]
        }
      ],
      "source": [
        "import torchvision.models\n",
        "alexnet = torchvision.models.alexnet(pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "oX7SjVdB7XAE",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "features = alexnet.features(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "TBo1BpL373LX",
        "jupyter": {
          "outputs_hidden": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b9dc010-0ec8-4af9-da63-ad8b2d453932"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torchvision.models\n",
        "\n",
        "#save features\n",
        "n= 0\n",
        "\n",
        "#creating loader arays again because feature extraction will use a different batch size\n",
        "train_loader2 = torch.utils.data.DataLoader(dataset, batch_size = 1, num_workers = 1, sampler = train_sampler)\n",
        "val_loader2 = torch.utils.data.DataLoader(dataset, batch_size = 1, num_workers = 1, sampler = val_sampler)\n",
        "test_loader2 = torch.utils.data.DataLoader(dataset, batch_size = 1, num_workers = 1, sampler = test_sampler)\n",
        "\n",
        "n=0\n",
        "for images, labels in train_loader2:\n",
        "  features = alexnet.features(images)\n",
        "  f_tensor_train= torch.from_numpy(features.detach().numpy())\n",
        "\n",
        "  n+=1\n",
        "\n",
        "n=0\n",
        "for images, labels in val_loader2:\n",
        "  features = alexnet.features(images)\n",
        "  f_tensor_val = torch.from_numpy(features.detach().numpy())\n",
        "\n",
        "  n+=1\n",
        "\n",
        "n=0\n",
        "for images, labels in test_loader2:\n",
        "  features = alexnet.features(images)\n",
        "  f_tensor_test = torch.from_numpy(features.detach().numpy())\n",
        "\n",
        "  n+=1\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_feat = torch.utils.data.DataLoader(f_tensor_train, batch_size = 30, num_workers = 1, shuffle = True)\n",
        "val_feat = torch.utils.data.DataLoader(f_tensor_val, batch_size = 30, num_workers = 1, shuffle = True)\n",
        "\n",
        "itera = iter(train_feat)\n",
        "features,labels = itera.next()\n",
        "print(features)\n",
        "print(labels)"
      ],
      "metadata": {
        "id": "BhWDTOdCNePC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "torch.manual_seed(1000)\n",
        "\n",
        "class AlexNetClass(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(AlexNetClass, self).__init__()\n",
        "    self.name = \"AlexNet\"\n",
        "    self.conv1=nn.Conv2d(200,400,3)\n",
        "    self.pool = nn.MaxPool2d(2,2)\n",
        "\n",
        "    self.x = floor((6-3+1)/2)\n",
        "    self.input = 400*self.x * self.x\n",
        "\n",
        "    self.fc1=nn.Linear(self.input, 32)\n",
        "    self.fc2 = nn.Linear(32,10)\n",
        "\n",
        "  def forward(self, features):\n",
        "    x = self.pool(F.relu(self.conv1(features)))\n",
        "    x = x.view(-1, self.input)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    return F.softmax(x, dim = 1)\n",
        "\n"
      ],
      "metadata": {
        "id": "o_aE3XffIBEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "oVTuHUeV78-U",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# features = ... load precomputed alexnet.features(img) ...\n",
        "output = model(features)\n",
        "prob = F.softmax(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "JCmiH11x7-q1",
        "jupyter": {
          "outputs_hidden": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "309f5ef8-20db-4b32-b5cf-5579031dbdc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-5c39fe633e77>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mAlexNetClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-57-ad85e9cef241>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_Loader, learning_rate, batch_size, num_epochs)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m#labels = labels.cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-59-3803ac822587>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [400, 200, 3, 3], expected input[30, 3, 224, 224] to have 200 channels, but got 3 channels instead"
          ]
        }
      ],
      "source": [
        "net= AlexNetClass()\n",
        "\n",
        "train_err, val_err, epochs = train(net, train_loader, val_loader)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}